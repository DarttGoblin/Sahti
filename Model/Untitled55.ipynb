{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/hackAI/dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oCDbik_-LfmB",
        "outputId": "bbe61eb5-b33f-4a50-9f9a-63b7054fb007"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/hackAI/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p normal. abnormal"
      ],
      "metadata": {
        "id": "EYS02rehLDs6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mv N*.wav normal/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUR_V2F0L-DJ",
        "outputId": "e93a12e7-9063-4bcc-c549-df9258fcb0a6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: target 'normal/' is not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv *.wav abnormal/"
      ],
      "metadata": {
        "id": "xJWcVAReNHoP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R19SowhKuv3P",
        "outputId": "ecce3a8f-184b-4e72-fc5c-f6dbc16574d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-05-25 07:07:29.168760: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1748156849.193272   11995 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1748156849.200401   11995 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-05-25 07:07:29.224492: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Using device: cpu\n",
            "Pre-trained model: facebook/wav2vec2-base\n",
            "Loading heartbeat dataset...\n",
            "Warning: Directory /content/drive/MyDrive/hackAI/dataset/normal not found!\n",
            "Loading abnormal samples from /content/drive/MyDrive/hackAI/dataset/abnormal\n",
            "Found 872 abnormal samples\n",
            "Total samples loaded: 872\n",
            "Normal samples: 0\n",
            "Abnormal samples: 872\n",
            "Total unique subjects: 109\n",
            "Subjects with normal recordings: 0\n",
            "Subjects with abnormal recordings: 109\n",
            "\n",
            "Performing subject-based train-validation split...\n",
            "\n",
            "Subject distribution:\n",
            "Normal-only subjects: 0\n",
            "Abnormal-only subjects: 109\n",
            "Unique Normal-only subjects: 0\n",
            "Unique Abnormal-only subjects: 109\n",
            "Mixed subjects (both normal and abnormal): 0\n",
            "âœ“ No subject overlap between train and validation sets\n",
            "\n",
            "Train subjects: 88\n",
            "Validation subjects: 21\n",
            "Training samples: 704 (Normal: 0, Abnormal: 704)\n",
            "Validation samples: 168 (Normal: 0, Abnormal: 168)\n",
            "Loading pre-trained model: facebook/wav2vec2-base\n",
            "config.json: 100% 1.84k/1.84k [00:00<00:00, 10.2MB/s]\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "pytorch_model.bin: 100% 380M/380M [00:06<00:00, 56.9MB/s]\n",
            "preprocessor_config.json: 100% 159/159 [00:00<00:00, 905kB/s]\n",
            "Encoder weights frozen for linear probing\n",
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "Feature dimension: 768\n",
            "Extracting training features...\n",
            "Extracting features using pre-trained encoder...\n",
            "Extracting features:   0% 0/44 [00:00<?, ?it/s]\n",
            "model.safetensors:   0% 0.00/380M [00:00<?, ?B/s]\u001b[A\n",
            "model.safetensors:   3% 10.5M/380M [00:00<00:10, 36.4MB/s]\u001b[A\n",
            "model.safetensors:   6% 21.0M/380M [00:00<00:07, 46.3MB/s]\u001b[A\n",
            "model.safetensors:   8% 31.5M/380M [00:00<00:06, 50.8MB/s]\u001b[A\n",
            "model.safetensors:  11% 41.9M/380M [00:00<00:07, 46.3MB/s]\u001b[A\n",
            "model.safetensors:  14% 52.4M/380M [00:01<00:06, 50.1MB/s]\u001b[A\n",
            "model.safetensors:  17% 62.9M/380M [00:01<00:06, 52.0MB/s]\u001b[A\n",
            "model.safetensors:  19% 73.4M/380M [00:01<00:05, 54.0MB/s]\u001b[A\n",
            "model.safetensors:  22% 83.9M/380M [00:01<00:05, 55.3MB/s]\u001b[A\n",
            "model.safetensors:  25% 94.4M/380M [00:01<00:05, 54.2MB/s]\u001b[A\n",
            "model.safetensors:  28% 105M/380M [00:02<00:04, 56.8MB/s] \u001b[A\n",
            "model.safetensors:  30% 115M/380M [00:02<00:04, 57.1MB/s]\u001b[A\n",
            "model.safetensors:  33% 126M/380M [00:02<00:04, 57.3MB/s]\u001b[A\n",
            "model.safetensors:  36% 136M/380M [00:02<00:04, 56.7MB/s]\u001b[A\n",
            "model.safetensors:  39% 147M/380M [00:02<00:04, 56.9MB/s]\u001b[A\n",
            "model.safetensors:  41% 157M/380M [00:02<00:03, 57.3MB/s]\u001b[A\n",
            "model.safetensors:  44% 168M/380M [00:03<00:03, 57.2MB/s]\u001b[A\n",
            "model.safetensors:  47% 178M/380M [00:03<00:03, 57.2MB/s]\u001b[A\n",
            "model.safetensors:  50% 189M/380M [00:03<00:03, 57.4MB/s]\u001b[A\n",
            "model.safetensors:  52% 199M/380M [00:03<00:03, 56.2MB/s]\u001b[A\n",
            "model.safetensors:  55% 210M/380M [00:03<00:02, 57.8MB/s]\u001b[A\n",
            "model.safetensors:  58% 220M/380M [00:04<00:02, 57.7MB/s]\u001b[A\n",
            "model.safetensors:  61% 231M/380M [00:04<00:02, 57.4MB/s]\u001b[A\n",
            "model.safetensors:  63% 241M/380M [00:04<00:02, 57.7MB/s]\u001b[A\n",
            "model.safetensors:  66% 252M/380M [00:04<00:02, 57.3MB/s]\u001b[A\n",
            "model.safetensors:  69% 262M/380M [00:04<00:02, 55.2MB/s]\u001b[A\n",
            "model.safetensors:  72% 273M/380M [00:04<00:01, 55.9MB/s]\u001b[A\n",
            "model.safetensors:  74% 283M/380M [00:05<00:01, 56.4MB/s]\u001b[A\n",
            "model.safetensors:  77% 294M/380M [00:05<00:01, 56.7MB/s]\u001b[A\n",
            "model.safetensors:  80% 304M/380M [00:05<00:01, 56.9MB/s]\u001b[A\n",
            "model.safetensors:  83% 315M/380M [00:05<00:01, 56.6MB/s]\u001b[A\n",
            "model.safetensors:  85% 325M/380M [00:05<00:00, 57.2MB/s]\u001b[A\n",
            "model.safetensors:  88% 336M/380M [00:06<00:00, 55.1MB/s]\u001b[A\n",
            "model.safetensors:  91% 346M/380M [00:06<00:00, 54.6MB/s]\u001b[A\n",
            "model.safetensors:  94% 357M/380M [00:06<00:00, 55.5MB/s]\u001b[A\n",
            "model.safetensors:  97% 367M/380M [00:06<00:00, 56.0MB/s]\u001b[A\n",
            "model.safetensors: 100% 380M/380M [00:06<00:00, 55.6MB/s]\n",
            "Extracting features: 100% 44/44 [20:10<00:00, 27.50s/it]\n",
            "Extracted features shape: torch.Size([704, 768])\n",
            "Extracting validation features...\n",
            "Extracting features using pre-trained encoder...\n",
            "Extracting features: 100% 11/11 [04:37<00:00, 25.26s/it]\n",
            "Extracted features shape: torch.Size([168, 768])\n",
            "Feature dimension: 768\n",
            "Training heartbeat classifier...\n",
            "Training heartbeat classifier...\n",
            "Epoch 0/200: Train Loss: 0.1260, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 1/200: Train Loss: 0.0001, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 2/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 3/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 4/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 5/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 6/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 7/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 8/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 9/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Epoch 20/200: Train Loss: 0.0000, Val Acc: 1.0000, Best Val Acc: 1.0000\n",
            "Early stopping at epoch 25 (patience: 25)\n",
            "\n",
            "=== HEARTBEAT CLASSIFICATION RESULTS ===\n",
            "Best Validation Accuracy: 1.0000\n",
            "Final Test Accuracy: 1.0000\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00       168\n",
            "\n",
            "    accuracy                           1.00       168\n",
            "   macro avg       1.00      1.00      1.00       168\n",
            "weighted avg       1.00      1.00      1.00       168\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[TN, FP],\n",
            " [FN, TP]]\n",
            "[[168]]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/hackAI/main_cross_patients_3.py\", line 745, in <module>\n",
            "    main()\n",
            "  File \"/content/drive/MyDrive/hackAI/main_cross_patients_3.py\", line 664, in main\n",
            "    tn, fp, fn, tp = cm.ravel()\n",
            "    ^^^^^^^^^^^^^^\n",
            "ValueError: not enough values to unpack (expected 4, got 1)\n"
          ]
        }
      ],
      "source": [
        "!python /content/drive/MyDrive/hackAI/main_cross_patients_3.py --data_dir /content/drive/MyDrive/hackAI/dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchaudio\n",
        "from main_cross_patients_3 import HeartbeatLinearProbe, PretrainedAudioEncoder\n",
        "\n",
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "INPUT_DIM = 768\n",
        "# Load model\n",
        "checkpoint_path = \"/content/dataset/best_heartbeat_classifier.pth\"\n",
        "checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "model = HeartbeatLinearProbe(INPUT_DIM)\n",
        "model.load_state_dict(checkpoint.get('model_state_dict', checkpoint))\n",
        "model.to(device).eval()\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "oWj3ry5FApka",
        "outputId": "e3c06e2a-3866-4bde-f99a-cd6dd0770bdd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'main_cross_patients_3'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-02e6cf6865b5>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchaudio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmain_cross_patients_3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mHeartbeatLinearProbe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPretrainedAudioEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'main_cross_patients_3'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_length = 16000*5\n",
        "PATH_AUDIO = \"/content/dataset/normal/N_089_sit_Aor.wav\"\n",
        " # Load audio\n",
        "waveform, sr = torchaudio.load(PATH_AUDIO )\n",
        "\n",
        "# Resample if necessary\n",
        "if sr != 1600:\n",
        "    resampler = T.Resample(sr, 16000)\n",
        "    waveform = resampler(waveform)\n",
        "\n",
        "# Convert to mono if stereo\n",
        "if waveform.shape[0] > 1:\n",
        "    waveform = torch.mean(waveform, dim=0, keepdim=True)\n",
        "\n",
        "# Flatten to 1D\n",
        "waveform = waveform.squeeze(0)\n",
        "\n",
        "# Pad or truncate to fixed length\n",
        "if waveform.shape[0] > target_length :\n",
        "    # For heartbeat sounds, take center portion to preserve the main heartbeat\n",
        "    start_idx = (waveform.shape[0] - target_length ) // 2\n",
        "    waveform = waveform[start_idx:start_idx + target_length ]\n",
        "else:\n",
        "    padding = target_length  - waveform.shape[0]\n",
        "    waveform = torch.nn.functional.pad(waveform, (padding//2, padding - padding//2))\n",
        "\n",
        "# Normalize audio\n",
        "if torch.std(waveform) > 0:\n",
        "    waveform = (waveform - torch.mean(waveform)) / torch.std(waveform)\n",
        "\n",
        "#return waveform, torch.tensor(self.labels[idx], dtype=torch.long), other_features (torch.tensor)\n",
        "encoder = PretrainedAudioEncoder()\n",
        "inputs = encoder(waveform.unsqueeze(0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7rdnayo5xuI",
        "outputId": "73f801d6-150c-4d05-8213-0c5a0fb70886"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pre-trained model: facebook/wav2vec2-base\n",
            "Encoder weights frozen for linear probing\n",
            "Feature dimension: 768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(inputs.to(device))\n",
        ""
      ],
      "metadata": {
        "id": "acWBKZG56LS4"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = torch.argmax(output , dim=1)\n",
        "predictions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0lxkKXyA9r-N",
        "outputId": "4e073808-e414-4cce-ec7b-1dcb023e2af0"
      },
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fnOgjlCk-SVN"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rZaaMuZOEdpR"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}